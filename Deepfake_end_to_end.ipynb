{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VinzentBuecheler/Deepfake/blob/main/Deepfake_end_to_end.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Fake Video Generator (Open in Google Colab)"
      ],
      "metadata": {
        "id": "8b01_lgx4oFg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Text translation"
      ],
      "metadata": {
        "id": "3i9Anxir9gfo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBxtacdf3URP",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Text Translation - Setup\n",
        "!pip install transformers torch espnet IPython espnet_model_zoo\n",
        "\n",
        "from transformers import FSMTForConditionalGeneration, FSMTTokenizer\n",
        "import time\n",
        "import torch\n",
        "from espnet2.bin.tts_inference import Text2Speech\n",
        "from espnet2.utils.types import str_or_none\n",
        "\n",
        "mname = \"facebook/wmt19-de-en\"\n",
        "tokenizer = FSMTTokenizer.from_pretrained(mname)\n",
        "model = FSMTForConditionalGeneration.from_pretrained(mname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "La5qopqI3URV",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Input a text in German { run: \"auto\" }\n",
        "input = \"Ich habe mich in eine Essiggurke verwandelt. Ich bin Essiggurke Rick!\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djCF2SLT3URV",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Translated text in English { run: \"auto\" }\n",
        "\n",
        "from IPython.display import Markdown as md\n",
        "\n",
        "input_ids = tokenizer.encode(input, return_tensors=\"pt\")\n",
        "outputs = model.generate(input_ids)\n",
        "decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "md(f'### The translated text is :  **{decoded} **')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Voice Cloning"
      ],
      "metadata": {
        "id": "F8iDoGMA6SxR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0yu3lZm3URY",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "#@title Voice Cloning - Setup\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "git_repo_url = 'https://github.com/CorentinJ/Real-Time-Voice-Cloning.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "if not exists(project_name):\n",
        "  # clone and install\n",
        "  !git clone -q --recursive {git_repo_url}\n",
        "  # install dependencies\n",
        "  !cd {project_name} && pip install -q -r requirements.txt\n",
        "  !pip install -q --upgrade gdown\n",
        "  !apt-get install -qq libportaudio2\n",
        "  !pip install -q https://github.com/tugstugi/dl-colab-notebooks/archive/colab_utils.zip\n",
        "\n",
        "  # download pretrained model\n",
        "  !cd {project_name} && wget https://github.com/blue-fish/Real-Time-Voice-Cloning/releases/download/v1.0/pretrained.zip && unzip -o pretrained.zip\n",
        "  !cd {project_name} && mkdir -p saved_models/default/\n",
        "  !cd {project_name}/saved_models/default/ && gdown https://drive.google.com/uc?id=1f9z6OHKwCRa7CteX6AV5XN68CCPHwCI1 #https://drive.google.com/uc?id=1q8mEGwCkFy23KZsinbuvdKAQLqNKbYf1\n",
        "  !cd {project_name}/saved_models/default/ && gdown https://drive.google.com/uc?id=19Uqcr2an7ha0Xymur4AtXV7a9lZN7mqj #https://drive.google.com/uc?id=1EqFMIbvxffxtjiVrtykroF6_mUh-5Z3s\n",
        "  !cd {project_name}/saved_models/default/ && gdown https://drive.google.com/uc?id=14qJzfTehtjvBwUBlWFWnvZnfYvT9m9aW #https://drive.google.com/uc?id=1cf2NO6FtI0jDuy8AV3Xgn6leO6dHjIgu\n",
        "\n",
        "import sys\n",
        "sys.path.append(project_name)\n",
        "\n",
        "from IPython.display import display, Audio, clear_output\n",
        "from IPython.utils import io\n",
        "import ipywidgets as widgets\n",
        "import numpy as np\n",
        "from dl_colab_notebooks.audio import record_audio, upload_audio\n",
        "\n",
        "from synthesizer.inference import Synthesizer\n",
        "from encoder import inference as encoder\n",
        "from vocoder import inference as vocoder\n",
        "from pathlib import Path\n",
        "\n",
        "!ls \n",
        "encoder.load_model(project_name / Path(\"saved_models/default/encoder.pt\")) #Path(\"/content/gdrive/MyDrive/Colab Notebooks/VoiceCloning_models/encoder.pt\") )\n",
        "synthesizer = Synthesizer(project_name / Path(\"saved_models/default/synthesizer.pt\")) #Path(\"/content/gdrive/MyDrive/Colab Notebooks/VoiceCloning_models/synthesizer.pt\") )\n",
        "vocoder.load_model(project_name / Path(\"saved_models/default/vocoder.pt\")) #Path(\"/content/gdrive/MyDrive/Colab Notebooks/VoiceCloning_models/vocoder.pt\") )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pre-Processing Audio \n",
        "#@markdown < The choosing of Personality should go here >\n",
        "\n",
        "#Fetch the Input audio file of Trump\n",
        "!cd sample_data && gdown https://drive.google.com/uc?id=1i0WhVsQh-7ptZQ5TTUfmsOo_yhnAqu3_\n",
        "\n",
        "SAMPLE_RATE = 22050\n",
        "# record_or_upload = \"Upload (.mp3 or .wav)\" #@param [\"Record\", \"Upload (.mp3 or .wav)\"]\n",
        "# record_seconds =   10#@param {type:\"number\", min:1, max:10, step:1}\n",
        "\n",
        "embedding = None\n",
        "def _compute_embedding(audio):\n",
        "  display(Audio(audio, rate=SAMPLE_RATE, autoplay=True))\n",
        "  global embedding\n",
        "  embedding = None\n",
        "  embedding = encoder.embed_utterance(encoder.preprocess_wav(audio, SAMPLE_RATE))\n",
        "def _record_audio(b):\n",
        "  clear_output()\n",
        "  audio = record_audio(record_seconds, sample_rate=SAMPLE_RATE)\n",
        "  _compute_embedding(audio)\n",
        "def _upload_audio(b):\n",
        "  clear_output()\n",
        "  audio = \"/content/sample_data/Trump_WEF_2018-trimmed.mp3\" #upload_audio(sample_rate=SAMPLE_RATE)\n",
        "  _compute_embedding(audio)\n",
        "\n",
        "# if record_or_upload == \"Record\":\n",
        "#   button = widgets.Button(description=\"Record Your Voice\")\n",
        "#   button.on_click(_record_audio)\n",
        "#   display(button)\n",
        "# else:\n",
        "  # button = widgets.Button(description=\"Upload Voice File\")\n",
        "  # button.on_click(_upload_audio)\n",
        "_upload_audio(\"\")"
      ],
      "metadata": {
        "id": "J7q31UxJ6aqt",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Generated Audio { run: \"auto\" }\n",
        "\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "text = decoded #\"Hello all. I am trying to help Venkat today. I hope he is using my audio for something useful. I am glad that I am able to help.\"\n",
        "  \n",
        "def synthesize(embed, text):\n",
        "  print(\"Synthesizing new audio...\")\n",
        "  #with io.capture_output() as captured:\n",
        "  specs = synthesizer.synthesize_spectrograms([text], [embed])\n",
        "  generated_wav = vocoder.infer_waveform(specs[0])\n",
        "  generated_wav = np.pad(generated_wav, (0, synthesizer.sample_rate), mode=\"constant\")\n",
        "  clear_output()\n",
        "  display(Audio(generated_wav, rate=synthesizer.sample_rate, autoplay=False))\n",
        "\n",
        "  #Save the generated audio file in a directory.\n",
        "  scaled_audio = np.int16(generated_wav/np.max(np.abs(generated_wav)) * 32767)\n",
        "  write('voiceClone_output.wav', synthesizer.sample_rate, scaled_audio )\n",
        "\n",
        "if embedding is None:\n",
        "  print(\"Error fetching the reference audio file. Check the link to gdrive file\")\n",
        "else:\n",
        "  synthesize(embedding, text)\n"
      ],
      "metadata": {
        "id": "04TR-su26c71",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Lip Syncing"
      ],
      "metadata": {
        "id": "BNSDWQHQwZyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Lip sync - Setup { run: \"auto\" }\n",
        "\n",
        "!git clone https://github.com/Rudrabha/Wav2Lip.git\n",
        "!cd /content/Wav2Lip/checkpoints/ && gdown https://drive.google.com/uc?id=1by1m-0RCx5v34G0ejXy9Zt6wNueNaDpW\n",
        "\n",
        "!cd /content/Wav2Lip && pip install -r requirements.txt\n",
        "\n",
        "!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"Wav2Lip/face_detection/detection/sfd/s3fd.pth\"\n",
        "\n",
        "#Fetch reference video of Trump\n",
        "!cd /content/sample_data && gdown https://drive.google.com/uc?id=1KgJd4Jix3U7lr2BYymb5u8uGD0rjHzDW"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CKvD_G85wfgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Create the Lip Syncing { run: \"auto\" }\n",
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip.pth --face \"../sample_data/Trim.mp4\" --audio \"../voiceClone_output.wav\" #\"../trump_input.wav\" #\"../sample_data/input_audio.wav\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "1ItBgzeIwh3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title The generated Fake video { run: \"auto\" }\n",
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('/content/Wav2Lip/results/result_voice.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=700 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HCsFja3nworD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Deepfake end to end.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}